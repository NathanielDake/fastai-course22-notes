{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1000\n",
    "d = 48\n",
    "\n",
    "X = torch.randn((N, d))\n",
    "w = torch.randn((d, 1))\n",
    "b = torch.randn(1)\n",
    "y = torch.randn((N, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1000, 1]), torch.Size([1000, 1]), tensor(0.), tensor([22.4021]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Manual Pass\n",
    "z = X @ w + b\n",
    "a = z.clamp_min(0)\n",
    "mse_loss = (a - y).pow(2).mean(dim=0) \n",
    "\n",
    "z.shape, a.shape, a.min(), mse_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODOs\n",
    "* Add `forward` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear():\n",
    "    def __init__(self, w, b):\n",
    "        self.w = w\n",
    "        self.b = b\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return x @ self.w + self.b\n",
    "\n",
    "\n",
    "class Relu():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def __call__(self, a):\n",
    "        return a.clamp_min(0)\n",
    "\n",
    "\n",
    "class MSE():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def __call__(self, target, pred):\n",
    "        return (target - pred).pow(2).mean(dim=0)\n",
    "\n",
    "\n",
    "class Model():\n",
    "\n",
    "    def __init__(self, w, b):\n",
    "        self.layers = [\n",
    "            Linear(w, b),\n",
    "            Relu()\n",
    "        ]\n",
    "        self.loss = MSE()\n",
    "\n",
    "    def __call__(self, x, y):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return self.loss(y, x)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensure the forward Pass is correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([22.4021])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# No wrapping via Model\n",
    "linear_layer1 = Linear(w, b)\n",
    "z = linear_layer1(X)\n",
    "a = Relu()(z)\n",
    "MSE()(y, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([22.4021])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Wrapping via Model\n",
    "model = Model(w, b)\n",
    "model(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute gradient via pytorch so we have a baseline to compare against"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear():\n",
    "    def __init__(self, w, b):\n",
    "        self.w = w\n",
    "        self.b = b\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return x @ self.w + self.b\n",
    "\n",
    "\n",
    "class Relu():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def __call__(self, a):\n",
    "        a.retain_grad()\n",
    "        self.a = a\n",
    "        return a.clamp_min(0)\n",
    "\n",
    "\n",
    "class MSE():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def __call__(self, target, pred):\n",
    "        pred.retain_grad()\n",
    "        self.target = target\n",
    "        self.pred = pred\n",
    "        return (target - pred).pow(2).mean(dim=0)\n",
    "\n",
    "\n",
    "class Model():\n",
    "\n",
    "    def __init__(self, w, b):\n",
    "        self.layers = [\n",
    "            Linear(w, b),\n",
    "            Relu()\n",
    "        ]\n",
    "        self.loss = MSE()\n",
    "\n",
    "    def __call__(self, x, y):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return self.loss(y, x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mkgrad(x): \n",
    "    return x.clone().requires_grad_(True)\n",
    "\n",
    "chks = w, b, X\n",
    "ptgrads = w_prime, b_prime, X_prime = tuple(map(mkgrad, chks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_prime = Model(w_prime, b_prime)\n",
    "loss_prime = model_prime(X_prime, y)\n",
    "loss_prime.backward()\n",
    "\n",
    "# w_prime.grad, b_prime.grad, model_prime.loss.pred.grad[0:10], model_prime.layers[-1].a.grad[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update classes to compute gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear():\n",
    "    def __init__(self, w, b):\n",
    "        self.w = w\n",
    "        self.b = b\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return x @ self.w + self.b\n",
    "\n",
    "    def backward(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "class Relu():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def __call__(self, a):\n",
    "        return a.clamp_min(0)\n",
    "    \n",
    "    def backward(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "class MSE():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def __call__(self, target, pred):\n",
    "        self.pred = pred\n",
    "        self.target = target\n",
    "        self.out = (target - pred).pow(2).mean(dim=0)\n",
    "        return self.out \n",
    "    \n",
    "    def backward(self):\n",
    "        N = self.target.shape[0]\n",
    "        pred = self.pred\n",
    "        target = self.target\n",
    "\n",
    "        dloss_dpred = (2 / N) * (pred - target)\n",
    "        self.pred.g = dloss_dpred\n",
    "\n",
    "\n",
    "\n",
    "class Model():\n",
    "    def __init__(self, w, b):\n",
    "        self.layers = [\n",
    "            Linear(w, b),\n",
    "            Relu()\n",
    "        ]\n",
    "        self.loss = MSE()\n",
    "\n",
    "    def __call__(self, x, y):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return self.loss(y, x)\n",
    "    \n",
    "    def backward(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([22.4021])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Wrapping via Model\n",
    "model = Model(w, b)\n",
    "loss = model(X, y)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0011],\n",
       "        [ 0.0007],\n",
       "        [ 0.0097],\n",
       "        [ 0.0003],\n",
       "        [ 0.0120],\n",
       "        [ 0.0025],\n",
       "        [-0.0007],\n",
       "        [ 0.0117],\n",
       "        [ 0.0010],\n",
       "        [ 0.0007]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.loss.pred.g[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0011],\n",
       "        [ 0.0007],\n",
       "        [ 0.0097],\n",
       "        [ 0.0003],\n",
       "        [ 0.0120],\n",
       "        [ 0.0025],\n",
       "        [-0.0007],\n",
       "        [ 0.0117],\n",
       "        [ 0.0010],\n",
       "        [ 0.0007]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000],\n",
       "        [0.0000],\n",
       "        [0.0097],\n",
       "        [0.0000],\n",
       "        [0.0120],\n",
       "        [0.0000],\n",
       "        [0.0000],\n",
       "        [0.0117],\n",
       "        [0.0000],\n",
       "        [0.0000]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
